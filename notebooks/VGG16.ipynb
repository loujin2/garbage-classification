{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam, Nadam\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/NEU/EAI6000/split-garbage-dataset/split-garbage-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        rotation_range = 20,\n",
    "        width_shift_range = 0.2,\n",
    "        height_shift_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        vertical_flip = True,\n",
    "        fill_mode='nearest'\n",
    ")\n",
    "validation_data = ImageDataGenerator(\n",
    "        rescale = 1./255\n",
    ")\n",
    "test_data = ImageDataGenerator(\n",
    "        rescale = 1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1768 images belonging to 6 classes.\n",
      "Found 328 images belonging to 6 classes.\n",
      "Found 431 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "set_shape = (200, 200, 3)\n",
    "\n",
    "train_batch_size = 256\n",
    "val_batch_size = 16\n",
    "\n",
    "train_generator = train_data.flow_from_directory(\n",
    "            path + '/train',\n",
    "            target_size = (set_shape[0], set_shape[1]),\n",
    "            batch_size = train_batch_size,\n",
    "            class_mode = 'categorical',)\n",
    "\n",
    "validation_generator = validation_data.flow_from_directory(\n",
    "            path + '/valid',\n",
    "            target_size = (set_shape[0], set_shape[1]),\n",
    "            batch_size = val_batch_size,\n",
    "            class_mode = 'categorical',\n",
    "            shuffle=False)\n",
    "\n",
    "test_generator = test_data.flow_from_directory(\n",
    "            path + '/test',\n",
    "            target_size = (set_shape[0], set_shape[1]),\n",
    "            batch_size = val_batch_size,\n",
    "            class_mode = 'categorical',\n",
    "            shuffle=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(weights = 'imagenet', include_top = False,input_shape = set_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers[:-3]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(vgg)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 6, 6, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 33,596,230\n",
      "Trainable params: 23,601,158\n",
      "Non-trainable params: 9,995,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Nadam(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-e2c209c26c24>:12: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.46951, saving model to VGG16 Garbage Classifier.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.46951 to 0.58232, saving model to VGG16 Garbage Classifier.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.58232 to 0.61585, saving model to VGG16 Garbage Classifier.h5\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.61585\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.61585 to 0.73171, saving model to VGG16 Garbage Classifier.h5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.73171 to 0.73476, saving model to VGG16 Garbage Classifier.h5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.73476 to 0.74085, saving model to VGG16 Garbage Classifier.h5\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.74085\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.74085 to 0.76524, saving model to VGG16 Garbage Classifier.h5\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.76524 to 0.80488, saving model to VGG16 Garbage Classifier.h5\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.80488\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.80488 to 0.81402, saving model to VGG16 Garbage Classifier.h5\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.81402\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.81402\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.81402 to 0.83232, saving model to VGG16 Garbage Classifier.h5\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.83232\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.83232\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.83232 to 0.84451, saving model to VGG16 Garbage Classifier.h5\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.84451\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.84451\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "mc = ModelCheckpoint('VGG16 Garbage Classifier.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "    verbose=0,\n",
    "    callbacks = [es, mc],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = model.evaluate_generator(test_generator, 431/val_batch_size, workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Loss:  0.6665012836456299 Test_Accuracy:  0.7587006688117981\n"
     ]
    }
   ],
   "source": [
    "print(\"Test_Loss: \", test_score[0], \"Test_Accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16 model has a good performance on the train and validation set. However, the performance declined a little on the test set, which reduced the prediction accuracy. It appears that this model has overfitting issue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
